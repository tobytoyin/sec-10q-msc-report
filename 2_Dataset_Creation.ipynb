{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset Creation",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uUCbh-MEY5U3D9E_5R14opIiQnW8MtIV",
      "authorship_tag": "ABX9TyMfXeAXsCMP0j6lMXb9Y8dY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobytoyin/sec-10q-msc-report/blob/main/2_Dataset_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCfh-GAA83gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbbc5f5-d709-461f-b5b9-e8b2351b6f80"
      },
      "source": [
        "import json\n",
        "import pandas as pd \n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "\n",
        "## load the base\n",
        "base_dir = \"/content/drive/MyDrive/Aston/Term 3/data\"\n",
        "training_dir = '/content/drive/MyDrive/Aston/Term 3/ML-training/datasets/'\n",
        "\n",
        "## load the set of paths r\n",
        "with open(f'{base_dir}/file_paths.json', 'r') as f:\n",
        "  paths = json.load(f)\n",
        "\n",
        "def read_fin_data(path):\n",
        "  # load the financial ratio as base dataframe \n",
        "  df = pd.read_csv(path, index_col=0)\n",
        "  df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
        "  df = df.fillna(value=np.nan)\n",
        "  return df\n",
        "\n",
        "paths"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'10_q_doc_path': '/content/drive/MyDrive/Aston/Term 3/data/datasets/text_data_lg.csv',\n",
              " 'balsheet_path': '/content/drive/MyDrive/Aston/Term 3/data/datasets/balsheet.csv',\n",
              " 'base_dir': '/content/drive/MyDrive/Aston/Term 3/data',\n",
              " 'cashflow': '/content/drive/MyDrive/Aston/Term 3/data/datasets/cashflow.csv',\n",
              " 'companies_path': '/content/drive/MyDrive/Aston/Term 3/data/selected_companies.csv',\n",
              " 'filing_original_dir': '/content/drive/MyDrive/Aston/Term 3/data/10-Q-original',\n",
              " 'filing_records_path': '/content/drive/MyDrive/Aston/Term 3/data/edgar-filing-parsing-full.csv',\n",
              " 'fin_price_path': '/content/drive/MyDrive/Aston/Term 3/data/datasets/daily_price.csv',\n",
              " 'fin_ratio_cont': '/content/drive/MyDrive/Aston/Term 3/data/datasets/financial_data_continous.csv',\n",
              " 'fin_ratio_path': '/content/drive/MyDrive/Aston/Term 3/data/datasets/financial_data.csv',\n",
              " 'metrics_path': '/content/drive/MyDrive/Aston/Term 3/data/datasets/metrics_data.csv',\n",
              " 'models_dir': '/content/drive/MyDrive/Aston/Term 3/data/models',\n",
              " 'snp_path': '/content/drive/MyDrive/Aston/Term 3/data/datasets/snp_data.csv',\n",
              " 'statement_path': '/content/drive/MyDrive/Aston/Term 3/data/datasets/statement.csv',\n",
              " 'tech_ind': '/content/drive/MyDrive/Aston/Term 3/data/datasets/tech_ind.csv'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yrocMTJE24E"
      },
      "source": [
        "### Define The Financial Variables In Here ### \n",
        "fund_include = [\n",
        "                'netAssets', 'BP', 'DP', 'currentRatio', \n",
        "                'SP', 'CFP', 'ROE', 'ROA', 'roic', 'peRatio', 'pbRatio', 'eps',\n",
        "                'EquityRatio', 'assetsTurnover', 'marketCap'\n",
        "                ]\n",
        "\n",
        "fund_without_pct = ['dividendPayoutRatio', 'dividendYield',\n",
        "                    'symbol', 'fillingDate', 'period']                \n",
        "\n",
        "                   ## percentage change only\n",
        "fund_pct_only = ['revenue', 'totalAssets', 'capitalExpenditure']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM1_JKsh848c"
      },
      "source": [
        "ratio_df = read_fin_data(paths['fin_ratio_path'])\n",
        "balsheet_df = read_fin_data(paths['balsheet_path'])\n",
        "metric_df = read_fin_data(paths['metrics_path'])\n",
        "statement_df = read_fin_data(paths['statement_path'])\n",
        "cashflow_df = read_fin_data(paths['cashflow'])\n",
        "tech_ind_df = read_fin_data(paths['tech_ind'])\n",
        "statement_df['fillingDate'] = pd.to_datetime(statement_df['fillingDate'], format='%Y-%m-%d')\n",
        "balsheet_df['filingDate'] = pd.to_datetime(balsheet_df['fillingDate'], format='%Y-%m-%d')\n",
        "cashflow_df['filingDate'] = pd.to_datetime(cashflow_df['fillingDate'], format='%Y-%m-%d')\n",
        "\n",
        "\n",
        "# # load the stock price data \n",
        "stock_df = pd.read_csv(paths['fin_price_path'], header=[0,1], index_col=0)\n",
        "stock_df.index = pd.to_datetime(stock_df.index, format='%Y-%m-%d')\n",
        "stock_df = stock_df.fillna(value=np.nan)\n",
        "\n",
        "snp_df = pd.read_csv(paths['snp_path'], index_col=0)\n",
        "vix_df = pd.read_csv('/content/drive/MyDrive/Aston/Term 3/data/datasets/vix.csv', index_col=0)\n",
        "\n",
        "# load the text data\n",
        "text_df = pd.read_csv(paths['10_q_doc_path'], index_col='acc_num')\n",
        "text_df['filing_date'] = pd.to_datetime(text_df['filing_date'], format='%Y-%m-%d')\n",
        "\n",
        "earnings_df = pd.read_csv('/content/drive/MyDrive/Aston/Term 3/data/datasets/earnings_sur.csv', index_col=0)\n",
        "earnings_df = earnings_df[['Symbol', 'filing_date', 'eps_sur', 'estimate_date', 'earning_sur_pct']]\n",
        "earnings_df['filing_date'] = pd.to_datetime(earnings_df['filing_date'], format='%Y-%m-%d')\n",
        "earnings_df['estimate_date'] = pd.to_datetime(earnings_df['estimate_date'], format='%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUaV-Us5CbuS"
      },
      "source": [
        "# earnings_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFjsMKBu714l"
      },
      "source": [
        "## Handle Merging similar DataFrames \n",
        "cols_to_use = metric_df.columns.difference(ratio_df.columns)\n",
        "cols_to_use = [*cols_to_use, 'date', 'symbol']\n",
        "\n",
        "fundamental_df = pd.merge(ratio_df, metric_df[cols_to_use], \n",
        "                          how='left', \n",
        "                          left_on=['date', 'symbol'], \n",
        "                          right_on=['date', 'symbol'])\n",
        "\n",
        "\n",
        "cols_to_use = statement_df.columns.difference(fundamental_df.columns)\n",
        "cols_to_use = [*cols_to_use, 'date', 'symbol']\n",
        "fundamental_df = pd.merge(fundamental_df, statement_df[cols_to_use], \n",
        "                          how='left', \n",
        "                          left_on=['date', 'symbol'], \n",
        "                          right_on=['date', 'symbol'])\n",
        "\n",
        "cols_to_use = balsheet_df.columns.difference(fundamental_df.columns)\n",
        "cols_to_use = [*cols_to_use, 'date', 'symbol']\n",
        "fundamental_df = pd.merge(fundamental_df, balsheet_df[cols_to_use], \n",
        "                          how='left', \n",
        "                          left_on=['date', 'symbol'], \n",
        "                          right_on=['date', 'symbol'])\n",
        "\n",
        "\n",
        "cols_to_use = cashflow_df.columns.difference(fundamental_df.columns)\n",
        "cols_to_use = [*cols_to_use, 'date', 'symbol']\n",
        "fundamental_df = pd.merge(fundamental_df, cashflow_df[cols_to_use], \n",
        "                          how='left', \n",
        "                          left_on=['date', 'symbol'], \n",
        "                          right_on=['date', 'symbol'])\n",
        "# list(ratio_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFeUBDm-JRFr"
      },
      "source": [
        "### Caluclate Some Financial Ratio ###\n",
        "fundamental_df.fillna(value={'dividendPayoutRatio': 0, \n",
        "                   'dividendPaidAndCapexCoverageRatio': 0, \n",
        "                   'dividendYield': 0, \n",
        "                   'totalCurrentLiabilities': 0, \n",
        "                   'longTermDebt': 0, \n",
        "                   'payoutRatio': 0}, inplace=True)\n",
        "\n",
        "fundamental_df['netAssets'] = fundamental_df['totalAssets'] - fundamental_df['totalLiabilities']\n",
        "fundamental_df['BP'] = fundamental_df['netAssets'] / fundamental_df['marketCap']\n",
        "fundamental_df['DP'] = fundamental_df['dividendsPaid'] / fundamental_df['marketCap']\n",
        "fundamental_df['SP'] = fundamental_df['revenue'] / fundamental_df['marketCap']\n",
        "fundamental_df['CFP'] = fundamental_df['operatingCashFlow'] / fundamental_df['marketCap']\n",
        "fundamental_df['ROE'] = fundamental_df['netIncome'] / fundamental_df['netAssets']\n",
        "fundamental_df['ROA'] = fundamental_df['operatingIncome'] / fundamental_df['totalAssets']\n",
        "fundamental_df['EquityRatio'] = fundamental_df['netAssets'] / fundamental_df['totalAssets']\n",
        "fundamental_df['assetsTurnover'] = fundamental_df['revenue'] / fundamental_df['totalAssets']\n",
        "fundamental_df['rd_mve'] = fundamental_df['researchAndDevelopmentExpenses'] / fundamental_df['marketCap']\n",
        "\n",
        "ratio_columns = fundamental_df.columns.drop(['symbol', 'date', 'period', 'link',\n",
        "                                             'filingDate', 'finalLink', 'acceptedDate',\n",
        "                                             'fillingDate', 'reportedCurrency'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdt9MiE17zcE",
        "outputId": "9df76799-57f1-469c-ce63-b119ff7a3847"
      },
      "source": [
        "# separate each stock into a dictionary\n",
        "stock_df_collections = {}\n",
        "fundamental_collections = {}\n",
        "\n",
        "idx = pd.IndexSlice\n",
        "companies = stock_df.columns.levels[1]\n",
        "\n",
        "############################# \n",
        "### Build Stock DataFrame ###report\n",
        "#############################\n",
        "time_index = stock_df.index # align every dataframe time index\n",
        "for company in companies:\n",
        "  empty_df = pd.DataFrame(index=stock_df.index)\n",
        "  # empty_df.index.name = 'Date'\n",
        "  company_stock = stock_df.loc[:, idx[:, company]].copy()\n",
        "\n",
        "  # drop level \n",
        "  company_stock = company_stock.droplevel(1, axis=1)\n",
        "  company_stock['symbol'] = company \n",
        "  company_stock = empty_df.join(company_stock)\n",
        "  company_stock.fillna(method='ffill', inplace=True, limit=2)\n",
        "  company_stock = company_stock.join(snp_df, \n",
        "                          how='left', rsuffix='_snp')\n",
        "  company_stock = company_stock.join(vix_df, \n",
        "                          how='left', rsuffix='_vix')\n",
        "  stock_df_collections[company] = company_stock\n",
        "\n",
        "############################# \n",
        "### Build Financial Ratio ###\n",
        "#############################\n",
        "for company in companies:\n",
        "  company_fund = fundamental_df.loc[fundamental_df['symbol'] == company].copy()\n",
        "\n",
        "  # replace these with zero \n",
        "  # dividend_cols = {'dividendPayoutRatio': 0, \n",
        "  #                  'dividendPaidAndCapexCoverageRatio': 0, \n",
        "  #                  'dividendYield': 0, \n",
        "  #                  'totalCurrentLiabilities': 0, \n",
        "  #                  'longTermDebt': 0, \n",
        "  #                  'payoutRatio': 0}\n",
        "  # company_fund.fillna(value=dividend_cols, inplace=True)\n",
        "\n",
        "  # backfill others by maximum 1 year\n",
        "  # company_fund.fillna(method='bfill', limit=4, inplace=True)\n",
        "  company_fund[ratio_columns].fillna(company_fund[ratio_columns].rolling(4, min_periods=1).mean().shift(-3), inplace=True)\n",
        "  company_fund.set_index('date', inplace=True)\n",
        "\n",
        "  # store in collection\n",
        "  fundamental_collections[company] = company_fund\n",
        "\n",
        "\n",
        "# fundamental_collections['AAPL'].head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4327: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd2yLLxk8_sE"
      },
      "source": [
        "def apply_to_companies(variable_name, func):\n",
        "  global stock_df_collections\n",
        "  for company in companies:\n",
        "    df = stock_df_collections[company].copy()\n",
        "    df[variable_name] = func(df)\n",
        "    stock_df_collections[company] = df\n",
        "\n",
        "def apply_to_fundamentals(variable_name, func):\n",
        "  global fundamental_collections\n",
        "  for company in companies:\n",
        "    df = fundamental_collections[company].copy()\n",
        "    df[variable_name] = func(df)\n",
        "    fundamental_collections[company] = df\n",
        "\n",
        "def get_price(df, col, new_shift):\n",
        "  return df[col].shift(new_shift)\n",
        "\n",
        "def substract(df, x, y):\n",
        "  return df[x] - df[y]\n",
        "\n",
        "def return_rate(df, new, old, new_shift=0, old_shift=1, normalize=True):\n",
        "  \"\"\"Calculate the Stock return by lag days\n",
        "\n",
        "  shift (positive) - past n days\n",
        "  shift (negative) - future n days\n",
        "  \"\"\"\n",
        "\n",
        "  # stock return \n",
        "  df = df.copy()\n",
        "\n",
        "  new_price = df[new]\n",
        "  old_price = df[old]\n",
        "\n",
        "  new_shifted = new_price.shift(new_shift)\n",
        "  old_shifted = old_price.shift(old_shift)\n",
        "\n",
        "  stock_return = (new_shifted / old_shifted) - 1\n",
        "\n",
        "  # snp_return \n",
        "  if normalize:\n",
        "    new_price = df[f\"{new}_snp\"]\n",
        "    old_price = df[f\"{old}_snp\"]\n",
        "\n",
        "    new_shifted = new_price.shift(new_shift)\n",
        "    old_shifted = old_price.shift(old_shift)\n",
        "\n",
        "    snp_return = (new_shifted / old_shifted) - 1\n",
        "    return stock_return - snp_return\n",
        "\n",
        "  return stock_return\n",
        "\n",
        "def volatility(df, window, normalize=True):\n",
        "  rates = return_rate(df, 'Close', 'Close', 1, 2, normalize)\n",
        "  result = rates.rolling(window, min_periods=1).std()\n",
        "  return result\n",
        "\n",
        "def skewness(df, window, normalize=True):\n",
        "  rates = return_rate(df, 'Close', 'Close', 1, 2, normalize)\n",
        "  # snp_rates = return_rate(df, 'Close_snp', 'Close_snp', 1, 2)\n",
        "\n",
        "  skew = rates.rolling(window, min_periods=1).skew()\n",
        "  return skew \n",
        "\n",
        "  snp_skew = snp_rates.rolling(window, min_periods=1).skew()\n",
        "\n",
        "  if normalize:\n",
        "    return skew - snp_skew\n",
        "\n",
        "  return skew\n",
        "\n",
        "def simple_moving_average(df, window, by='return_rate', normalize=True):\n",
        "  if by == 'return_rate':\n",
        "    rates = return_rate(df, 'Close', 'Close', 1, 2, normalize)\n",
        "  \n",
        "  else: \n",
        "    rates = get_price(df, by, 1)\n",
        "\n",
        "  mean = rates.rolling(window, min_periods=1).mean()\n",
        "  return mean\n",
        "\n",
        "def relative_strength_index(df, window, shift_start_date=1):\n",
        "  def sum_gt(x, gt=0):\n",
        "    return sum(filter(lambda a: a >= gt, x))\n",
        "\n",
        "  def sum_lt(x, lt=0):\n",
        "    return sum(filter(lambda a: a < lt, x))\n",
        "\n",
        "  # find the shift 1 day\n",
        "  difference = df['Close'].shift(shift_start_date).diff(1)\n",
        "  average_gain = difference.rolling(window).apply(sum_gt)\n",
        "  average_loss = difference.rolling(window).apply(sum_lt)\n",
        "\n",
        "  return 100 - (100 / (1 + (average_gain / -average_loss)))\n",
        "\n",
        "\n",
        "def chmom(df):\n",
        "  \"\"\"Return Month 6 to Month 1 - Month 12 to Month 7\"\"\"\n",
        "  month6_to_1 = return_rate(df, 'Close', 'Close', 31, 210)\n",
        "  month12_to_7 = return_rate(df, 'Close', 'Close', 210, 360)\n",
        "  return month6_to_1 - month12_to_7\n",
        "\n",
        "def ear(df):\n",
        "  rates = return_rate(df, 'Close', 'Close', 1, 2)\n",
        "  return rates.rolling(3).sum()\n",
        "\n",
        "def cal_shift(df, shift):\n",
        "  return df.shift(shift)\n",
        "\n",
        "## cash \n",
        "def cash_to_avg_assets(df):\n",
        "  # average assets \n",
        "  average_total_assets = df['totalAssets'].rolling(2).mean().shift(-1)\n",
        "  return df['cashAndCashEquivalents'] / average_total_assets\n",
        "\n",
        "def nincr(df):\n",
        "  \"\"\"Counts Num of increaseing earnings of 8 pervious quarters\"\"\"\n",
        "  window = 8\n",
        "  def count_consecutive(x):\n",
        "    count = 0\n",
        "    for i in x:\n",
        "      if i == 0:\n",
        "        return count\n",
        "      count += 1\n",
        "\n",
        "    return count\n",
        "  # Find Diff - if earning increases compare to the past \n",
        "  earning_diff = df['netIncome'].diff(-1)\n",
        "  if_earning_increase = earning_diff > 0\n",
        "  consecutive_num_increase_earning = (\n",
        "      if_earning_increase.rolling(window)\n",
        "      .apply(count_consecutive)\n",
        "      .shift(-window)\n",
        "  )\n",
        "\n",
        "  return consecutive_num_increase_earning\n",
        "\n",
        "def moving_average_future_return(df, days_after=60, period=5, normalize=True):\n",
        "  day_5 = return_rate(df, 'Open', 'Close', -period, 1, normalize)\n",
        "  # day_5 = return_rate(df, 'Open', 'Close', -period -1, -1)\n",
        "\n",
        "  for i in range(1, int(days_after / period)):\n",
        "    # print((i+1) * -5, ' --- ', i * -5)\n",
        "    day_5 += return_rate(df, 'Open', 'Close', (i+1) * -period, i * -period, normalize)\n",
        "\n",
        "  # print('--------------')\n",
        "  \n",
        "  # average = day_5 / 6  \n",
        "  return day_5\n",
        "\n",
        "\n",
        "#### Market Drift Period \n",
        "def post_filing_volatility(df, window=2, normalize=True):\n",
        "  rates = return_rate(df, 'Close', 'Close', -1, 1, normalize)\n",
        "  result = rates.rolling(window).std()\n",
        "  return result\n",
        "\n",
        "def post_filing_volumne(df):\n",
        "  rates = return_rate(df, 'Volume', 'Volume', -1, 1)\n",
        "  result = rates.rolling(2).mean()\n",
        "  return result\n",
        "\n",
        "def post_moving_average_future_return(df, days_after=60, period=5):\n",
        "  day_5 = return_rate(df, 'Open', 'Open', -period -2, -2)\n",
        "  # day_5 = return_rate(df, 'Open', 'Close', -period -1, -1)\n",
        "\n",
        "  for i in range(1, int(days_after / period)):\n",
        "    # print((i+1) * -period -2, i * -period - 2)\n",
        "    day_5 += return_rate(df, 'Open', 'Open', (i+1) * -period -2, i * -period - 2)\n",
        "\n",
        "  # print('--------------')\n",
        "  \n",
        "  # average = day_5 / 6  \n",
        "  return day_5  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKqUodxwJ5ao"
      },
      "source": [
        "apply_to_companies('y_return30_nom', lambda x: return_rate(x, 'Open', 'Close', -2, 1))\n",
        "# apply_to_companies('y_return30_snp', lambda x: return_rate(x, 'Open_snp', 'Close_snp', -30, 1))\n",
        "# apply_to_companies('y_return30_nom', lambda x: substract(x, 'y_return30', 'y_return30_snp'))\n",
        "# apply_to_companies('y_return30_nom', moving_average_future_return)\n",
        "# apply_to_companies('return30', lambda x: moving_average_future_return(x, normalize=False))\n",
        "\n",
        "# market drift within post filing period \n",
        "# apply_to_companies('y_return30_nom', post_moving_average_future_return)\n",
        "# apply_to_companies('post_filing_vol', post_filing_volatility)\n",
        "# apply_to_companies('post_filing_mom', lambda x: return_rate(x, 'Close', 'Close', -1, 1))  # 1 week\n",
        "# apply_to_companies('post_filing_vix', lambda x: get_price(x, 'Close_vix', -1))\n",
        "# apply_to_companies('post_filing_vix_pct', lambda x: return_rate(x, 'Close_vix', 'Close_vix', -1, 1, False))  # 1 week\n",
        "# apply_to_companies('post_filing_volume', post_filing_volumne)\n",
        "\n",
        "\n",
        "# get vix index \n",
        "apply_to_companies('vix_1', lambda x: get_price(x, 'Close_vix', 1))\n",
        "apply_to_companies('vix_pct30', lambda x: return_rate(x, 'Close_vix', 'Close_vix', 1, 31, False))  # 1 week\n",
        "# apply_to_companies('vix_pct60', lambda x: return_rate(x, 'Close_vix', 'Close_vix', 1, 61, False))  # 1 week\n",
        "# apply_to_companies('vix_pct90', lambda x: return_rate(x, 'Close_vix', 'Close_vix', 1, 91, False))  # 1 week\n",
        "\n",
        "# volume \n",
        "apply_to_companies('volume_7', lambda x: simple_moving_average(x, 7, 'Volume', False))\n",
        "apply_to_companies('volume_30', lambda x: simple_moving_average(x, 30, 'Volume', False))\n",
        "apply_to_companies('volume_60', lambda x: simple_moving_average(x, 60, 'Volume', False))\n",
        "apply_to_companies('volume_90', lambda x: simple_moving_average(x, 90, 'Volume', False))\n",
        "\n",
        "# price return Momentum\n",
        "apply_to_companies('mom_7', lambda x: return_rate(x, 'Close', 'Close', 1, 8))  # 1 week\n",
        "apply_to_companies('mom_30', lambda x: return_rate(x, 'Close', 'Close', 1, 31))  # 1 month\n",
        "apply_to_companies('mom_60', lambda x: return_rate(x, 'Close', 'Close', 1, 61))  # 2 months \n",
        "apply_to_companies('mom_90', lambda x: return_rate(x, 'Close', 'Close', 1, 91))  # 1 quarter \n",
        "apply_to_companies('mom_360', lambda x: return_rate(x, 'Close', 'Close', 1, 361))  # 1 year \n",
        "\n",
        "# momemtum of SnP\n",
        "# apply_to_companies('mom_7_snp', lambda x: return_rate(x, 'Close_snp', 'Close_snp', 1, 8, False))  # 1 week\n",
        "# apply_to_companies('mom_30_snp', lambda x: return_rate(x, 'Close_snp', 'Close_snp', 1, 31, False))  # 1 month\n",
        "\n",
        "# price return volataility\n",
        "apply_to_companies('volatility7', lambda x: volatility(x, 7))\n",
        "apply_to_companies('volatility30', lambda x: volatility(x, 30))\n",
        "apply_to_companies('volatility60', lambda x: volatility(x, 60))\n",
        "apply_to_companies('volatility90', lambda x: volatility(x, 90))\n",
        "apply_to_companies('volatility360', lambda x: volatility(x, 360))\n",
        "\n",
        "# apply_to_companies('retvol', lambda x: cal_shift(volatility(x, 30), 30))\n",
        "\n",
        "# skewness \n",
        "# apply_to_companies('skew7', lambda x: skewness(x, 7))\n",
        "# apply_to_companies('skew30', lambda x: skewness(x, 30))\n",
        "# apply_to_companies('skew60', lambda x: skewness(x, 60))\n",
        "# apply_to_companies('skew90', lambda x: skewness(x, 90))\n",
        "# apply_to_companies('skew360', lambda x: skewness(x, 360))\n",
        "\n",
        "# simple moving average of price returns \n",
        "apply_to_companies('sma7', lambda x: simple_moving_average(x, 7))\n",
        "apply_to_companies('sma30', lambda x: simple_moving_average(x, 30))\n",
        "apply_to_companies('sma60', lambda x: simple_moving_average(x, 60))\n",
        "apply_to_companies('sma90', lambda x: simple_moving_average(x, 90))\n",
        "\n",
        "# Relative Strength Index \n",
        "# apply_to_companies('rsi14', lambda x: relative_strength_index(x, 14))\n",
        "# apply_to_companies('chmom', chmom)\n",
        "# apply_to_companies('ear', ear)\n",
        "\n",
        "# ############## Apply to Fundamentals ################\n",
        "# apply_to_fundamentals('cash_avg_assets', cash_to_avg_assets)\n",
        "# apply_to_fundamentals('nincr', nincr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sYPDP2jJa2W"
      },
      "source": [
        "## Calculate Percentage For Selected Columns \n",
        "pct_change_col = fund_include + fund_pct_only\n",
        "\n",
        "for company in companies:\n",
        "  company_fund = fundamental_collections[company]\n",
        "  pct_cols = []\n",
        "  \n",
        "  # calcuate pct change\n",
        "  for col in pct_change_col:\n",
        "    # annuual percentage change \n",
        "    for i in [1, 4]:\n",
        "      col_name = f'{col}_pct{i}'\n",
        "      pct_change = company_fund[col].pct_change(-i)\n",
        "\n",
        "      # consider no percentage change as 0 change \n",
        "      pct_change.fillna(0, inplace=True)\n",
        "\n",
        "      company_fund[col_name] = pct_change\n",
        "      pct_cols.append(col_name)\n",
        "\n",
        "  # select features \n",
        "  company_fund = company_fund[[*fund_include, *pct_cols, *fund_without_pct]]\n",
        "  fundamental_collections[company] = company_fund"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ8dl9tk_k9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a933f98-21a2-4313-e7ba-3bf7e3a15425"
      },
      "source": [
        "full_data = pd.DataFrame()\n",
        "\n",
        "## Merge Fundamental to Stock Data (base on filing date)\n",
        "for company in companies:\n",
        "  fundemental = fundamental_collections.get(company)\n",
        "  stock_data  = stock_df_collections.get(company)\n",
        "\n",
        "  # merge fundamental with stock data\n",
        "  df = pd.merge(fundemental.reset_index(), \n",
        "                stock_data.reset_index(), \n",
        "                how='inner', \n",
        "                left_on=['fillingDate', 'symbol'], \n",
        "                right_on=['Date', 'symbol'])\n",
        "  \n",
        "  # merge with text data \n",
        "  df = pd.merge(df, text_df, \n",
        "                how='inner', \n",
        "                left_on=['fillingDate', 'symbol'], \n",
        "                right_on=['filing_date', 'sym'])\n",
        "\n",
        "  # shift 1 \n",
        "  df['return30_prev'] = df['y_return30_nom'].shift(-1)\n",
        "  \n",
        "  # combine \n",
        "  full_data = pd.concat([full_data, df])\n",
        "\n",
        "# combine with earnings \n",
        "def look_for_earnings(x, offset=0):\n",
        "  if offset > 60:\n",
        "    return 0\n",
        "  \n",
        "  date = x['fillingDate']\n",
        "  symbol = x['symbol']\n",
        "\n",
        "  match_date = earnings_df['estimate_date'] == date - pd.DateOffset(offset) \n",
        "  match_symbol = earnings_df['Symbol'] == symbol\n",
        "  earnings = earnings_df[match_date & match_symbol]['earning_sur_pct']\n",
        "\n",
        "  if earnings.empty:\n",
        "    offset += 1\n",
        "    return look_for_earnings(x, offset)\n",
        "\n",
        "  try: \n",
        "    return earnings.to_numpy()[0]\n",
        "  except IndexError:\n",
        "    return 0\n",
        "  \n",
        "full_data.shape\n",
        "\n",
        "full_data['eps_sur'] = full_data.apply(look_for_earnings, axis=1)\n",
        "print('FULL DATA: ', full_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL DATA:  (12903, 104)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26LhhElfoohW",
        "outputId": "68817b04-4a3a-4d89-d4ab-bbd03f7b406d"
      },
      "source": [
        "removal_data = full_data[full_data['Close'] > 5]\n",
        "removal_data.dropna(inplace=True)\n",
        "print('AFTER NA REMOVAL: ', removal_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AFTER NA REMOVAL:  (11966, 104)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2VwO5LSDy1F"
      },
      "source": [
        "removal_data = removal_data.drop(columns=['date', 'Date', \n",
        "                                    'fog_index', 'Unnamed: 0',\n",
        "                                    'Open_snp', 'High_snp', 'Low_snp', 'Close_snp', 'Adj Close_snp', 'Volume_snp',\n",
        "                                    'Open_vix', 'High_vix', 'Low_vix', 'Close_vix', 'Adj Close_vix', 'Volume_vix',\n",
        "                                    'Adj Close', 'High', 'Low', 'Open', 'Close'])\n",
        "\n",
        "# full_data.to_csv(f'{training_dir}/full2_data.csv')\n",
        "# full_data.to_csv(f'{training_dir}/full3_data.csv')\n",
        "# full_data.drop(columns=['10-q-text']).to_csv(f'{training_dir}/full_notext.csv')\n",
        "removal_data.to_csv(f'{training_dir}/full_data_lg2.csv')\n",
        "\n",
        "\n",
        "# full_data.drop(columns=['10-q-text']).to_csv(f'{base_dir}/full_notext.csv')\n",
        "# full_data.to_csv(f'{training_dir}/full_notext.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O6TeZ9EPhYB"
      },
      "source": [
        "# ### Testing ###\n",
        "# company = full_data['sym'] == 'AAPL'\n",
        "# date = full_data['filing_date'] == pd.Timestamp('2019-07-31')\n",
        "\n",
        "# full_data.loc[company & date][['y_return30_nom']]\n",
        "\n",
        "# # fundamental_collections['ACN'][['currentRatio', 'currentRatio_pct']]\n",
        "# full_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOsz8Do6sJaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad28bff-4a26-497a-d2a0-ffa1fb8051c3"
      },
      "source": [
        "for col in full_data.columns:\n",
        "  print(col, ' : ', end='')\n",
        "  print(np.sum(pd.isna(full_data[col])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date  : 0\n",
            "netAssets  : 1\n",
            "BP  : 1\n",
            "DP  : 1\n",
            "currentRatio  : 4\n",
            "SP  : 1\n",
            "CFP  : 1\n",
            "ROE  : 1\n",
            "ROA  : 1\n",
            "roic  : 5\n",
            "peRatio  : 7\n",
            "pbRatio  : 12\n",
            "eps  : 0\n",
            "EquityRatio  : 2\n",
            "assetsTurnover  : 1\n",
            "marketCap  : 1\n",
            "netAssets_pct1  : 0\n",
            "netAssets_pct4  : 0\n",
            "BP_pct1  : 0\n",
            "BP_pct4  : 0\n",
            "DP_pct1  : 0\n",
            "DP_pct4  : 0\n",
            "currentRatio_pct1  : 0\n",
            "currentRatio_pct4  : 0\n",
            "SP_pct1  : 0\n",
            "SP_pct4  : 0\n",
            "CFP_pct1  : 0\n",
            "CFP_pct4  : 0\n",
            "ROE_pct1  : 0\n",
            "ROE_pct4  : 0\n",
            "ROA_pct1  : 0\n",
            "ROA_pct4  : 0\n",
            "roic_pct1  : 0\n",
            "roic_pct4  : 0\n",
            "peRatio_pct1  : 0\n",
            "peRatio_pct4  : 0\n",
            "pbRatio_pct1  : 0\n",
            "pbRatio_pct4  : 0\n",
            "eps_pct1  : 0\n",
            "eps_pct4  : 0\n",
            "EquityRatio_pct1  : 0\n",
            "EquityRatio_pct4  : 0\n",
            "assetsTurnover_pct1  : 0\n",
            "assetsTurnover_pct4  : 0\n",
            "marketCap_pct1  : 0\n",
            "marketCap_pct4  : 0\n",
            "revenue_pct1  : 0\n",
            "revenue_pct4  : 0\n",
            "totalAssets_pct1  : 0\n",
            "totalAssets_pct4  : 0\n",
            "capitalExpenditure_pct1  : 0\n",
            "capitalExpenditure_pct4  : 0\n",
            "dividendPayoutRatio  : 0\n",
            "dividendYield  : 0\n",
            "symbol  : 0\n",
            "fillingDate  : 0\n",
            "period  : 0\n",
            "Date  : 0\n",
            "Adj Close  : 4\n",
            "Close  : 4\n",
            "High  : 4\n",
            "Low  : 4\n",
            "Open  : 4\n",
            "Volume  : 4\n",
            "Open_snp  : 2\n",
            "High_snp  : 2\n",
            "Low_snp  : 2\n",
            "Close_snp  : 2\n",
            "Adj Close_snp  : 2\n",
            "Volume_snp  : 2\n",
            "Open_vix  : 2\n",
            "High_vix  : 2\n",
            "Low_vix  : 2\n",
            "Close_vix  : 2\n",
            "Adj Close_vix  : 2\n",
            "Volume_vix  : 2\n",
            "y_return30_nom  : 33\n",
            "vix_1  : 14\n",
            "vix_pct30  : 16\n",
            "volume_7  : 4\n",
            "volume_30  : 4\n",
            "volume_60  : 4\n",
            "volume_90  : 4\n",
            "mom_7  : 35\n",
            "mom_30  : 26\n",
            "mom_60  : 46\n",
            "mom_90  : 58\n",
            "mom_360  : 275\n",
            "volatility7  : 4\n",
            "volatility30  : 4\n",
            "volatility60  : 4\n",
            "volatility90  : 4\n",
            "volatility360  : 4\n",
            "sma7  : 4\n",
            "sma30  : 4\n",
            "sma60  : 4\n",
            "sma90  : 4\n",
            "Unnamed: 0  : 0\n",
            "sym  : 0\n",
            "filing_date  : 0\n",
            "10-q-text  : 1\n",
            "fog_index  : 0\n",
            "return30_prev  : 341\n",
            "eps_sur  : 162\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}